---
layout: post
title: Agent的上下文工程
date: 2025-08-13
tags: [Agent, 上下文工程]
categories: agents
---

上下文工程是AI Agent中的一个技术方向。

典型Agent的工作模式为： 用户给定输入时，Agent通过调用一系列工具来完成任务。在每次迭代中，模型会根据当前上下文从预先定义好的动作空间中选择一个动作，然后该动作在环境中执行得到观察结果。动作和观察到的结果联合上下文，形成下一次迭代的输入，这样的迭代持续到任务结束。

从工作模式中可以看到，每次迭代随着步数的增加，输入的长度会增加，而输出一般是结构化的函数调用-“保持相对较短”。在Manus中，预填充和输出的长度比例在100:1。

KV缓存
对于有相同前缀的上下文可以使用KV缓存，这可以大大减少首令牌时间（TTFT）和推理成本。 那么如何提高缓存命中率呢？

1. 保持提示词的前缀稳定。

2. 使上下文仅追加。

3. 在需要时明确标记缓存断点。

如果使用vLLM或者SGlang等框架是，请确保启用了前缀/提示缓存，并且使用会话id等技术在分布式工作器之间一致地路由请求。

这里可以参考：kv cache

Mask
Agent承担更多的功能时，其动作空间就会变得更加复杂。简单的说，工具数量呈爆发式增长。MCP的流行只是火上浇油，如果你允许用户可配置的工具，有人会不可避免地会将数百个神秘工具插入到精心设计的动作空间里。这样会导致模型更可能选择错误的动作或采取低效的路径。笨重的Agent反而效果更差了。

这样一个很自然的思想是设计动态的动作空间---类似RAG的东西按需加载工具。 但据Manus的实验表明一个明确的规则：除非绝对必要，避免在迭代过程中动态添加或删除工具。原因有两个：

1. 在大多数LLM中，工具定义在序列化后位于上下文的前部附近，通常在系统提示词之前或之后。所以任何更改都会使所有后续动作和观察结果的KV缓存失效。

2. 当之前的动作和观察结果仍然引用当前上下文中不再定义的工作时，模型会感到困惑。没有约束解码，这通常会导致模式违规或幻觉动作。

为了解决这个问题，同时仍然改进动作选择，Manus使用上下文感知的state machine来管理工作可用性。它不是删除工具，而是在解码期间掩码令牌logits，以根据当前上下文防止（或者强制执行）某些动作的选择。

使用文件系统作为上下文
现代前沿LLM提供128K令牌或更多的上下文窗口。但在现实世界的Agent场景，这通常不够。有3个常见的痛点：

1. 观察结果可能很大，特别是当Agent与网页或PDF等非结构化数据交互式，很容易超过上下文限制。

2. 模型性能往往超过某个上下文长度后下降，即时窗口技术上支持它。

3. 长输入很昂贵，即使有前缀缓存，仍然需要为传输和预填充的每个token付费。

为处理这个问题，许多Agent系统实现上下文截断或压缩策略。但过于激进的压缩不可避免地导致信息丢失。问题是根本性的：Agent本质上必须基于所有先前状态预测下一个动作，你无法可靠地预测哪个观察结果可能在十步后变得关键。从逻辑上看，任何不可逆的压缩都带有风险。

因此将文件系统视为最终上下文：大小无限，本质持久，并且Agent本身可以直接操作。模型学会按需写入和读取文件--使用文件系统不仅仅是存储，而且作为结构化的、外部化的内存。 在开发这个功能时，我们可以想象状态空间模型SSM在Agent设置中有效工作需要什么。

注意力
在Manus中，处理复杂任务时，它倾向于创建一个todo.md文件，并在任务进行时逐步更新它，勾选已完成的项目。 这个是通过复述操纵注意力。 Manus中的典型任务平均需要大约50次工具调用。这是一个很长的循环-由于Manus依赖LLM进行决策，它容易偏离主题或忘记早期目标，特别是在长上下文或复杂的任务中。

通过不断重写待办事项列表，Manus正在将其目标复述到上下文的末尾。这样减少目标错位。

Agent犯错
语言模型产生幻觉，环境返回错误，外部工具行为不当，意外边缘情况总是出现。在多步骤任务中，失败不是例外，它是循环的一部分。 对于这种错误，一个很常见的行为是：清理跟踪，重试动作，或重置模型状态并留给神奇的temperature。这种行为存在的代价：擦除失败会移除证据，没有证据，模型就无法适应。

避免少样本陷阱
少样本提示（few-shot prompting）是改善LLM输出的常用技术。但在Agent系统中，它可能会适得其反。

语言模型是优秀的模仿者，它们模仿上下文中的行为模式。如果上下文充满了类似的过去动作观察对，模型倾向于遵循该模式，即使它不再是最优的。 解决方案是增加多样性。Manus在动作和观察中引入少量结构化变化 -- 不同的序列化模版、替代措辞、顺序或格式中的小噪声。

这种受控的随机性有助于打破模式并调整模型的注意力。